# 11. Why model?{-}

## Some concepts and points{-} 

- Estimand 

- Estimator

- We can not always let the data "speak for themselves" to obtain a meaningful estimate. Rather, we often need to supplement the data with a model. 

- What is a model? A model is defined by an a priori restriction on the joint distribution of the data. 

- When using a parametric model, the inferences are correct only if the restrictions encoded in the model are correct, i.e., if the model is correctly specified. Thus model-based causal inference relies on conditions of no model misspecification. 

- Fisher consistency: An estimator of a population quantity that, when calculated using the entire population rather than a sample, yields the true value of the population parameter. 

- Bias-variance trade-off


## Program 11.1{-}

- Sample averages by treatment level
- Data from Figures 11.1 and 11.2

```{r out.width="85%", fig.align='center'}
A<-c(rep(1, 8), rep(0, 8))
Y <- c(200, 150, 220, 110, 50, 180, 90, 170, 170, 30, 70, 110, 80, 50, 10, 20)
plot(A, Y, pch=16)
mean(Y[A == 0])
mean(Y[A == 1])
```


```{r out.width="85%", fig.align='center'}
A2<-c(rep(1,4), rep(2, 4), rep(3, 4), rep(4,4))
Y2 <- c(110, 80, 50, 40, 170, 30, 70, 50, 110, 50, 180, 130, 200, 150, 220, 210)
plot(A2, Y2, pch=16)
mean(Y2[A2 == 1])
mean(Y2[A2 == 2])
mean(Y2[A2 == 3])
mean(Y2[A2 == 4])
```


## Program 11.2{-}

- 2-parameter linear model
- Data from Figures 11.3 and 11.1

```{r out.width="85%", fig.align='center'}
A3 <-c(3, 11, 17, 23, 29, 37, 41, 53, 67, 79, 83, 97, 60, 71, 15, 45)
Y3 <-c(21, 54, 33, 101, 85, 65, 157, 120, 111, 200, 140, 220, 230, 217, 11, 190)
plot(Y3 ~ A3, pch=16)
summary(glm(Y3 ~ A3))
predict(glm(Y3 ~ A3), data.frame(A3 = 90))
summary(glm(Y ~ A))
```

## Program 11.3{-}

- 3-parameter linear model: $E(Y|A)=\theta_0+\theta_{1}A+\theta_{2}A^2$, where $A^2=A\times A$
- Data from Figure 11.3

```{r}
Asq <- A3 * A3
mod3 <- glm(Y3 ~ A3 + Asq)
summary(mod3)
predict(mod3, data.frame(cbind(A3 = 90, Asq = 8100)))
```





